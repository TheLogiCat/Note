### 1.1 机器学习开发流程

（1）获取数据

（2）数据处理

（3）特征工程

（4）机器学习算法训练 — 模型

（5）模型评估

（6）应用



### 2.1 数据集

####  	2.2.1 可用数据集

公司内部 百度

数据接口

数据集：

学习阶段可以使用的数据集：

​	（1）Scikit - sklearn

​	（2）kaggle

​	（3）UCI

#### 	2.1.2 sklearn数据集

##### 		1. **sklearn.datasets**

​	load_*	获得小规模数据集

​	fetch_*	获取大规模数据集（需要从网上下载）

##### 		2. **sklearn小数据集**

**​	sklearn.datasets.load_具体数据名()**

##### 		3. **sklearn大数据集**

​	**sklearn.datasets.fetch_具体数据名(data_home=None, subset='train')**

​	data_home表示文件下载的路径

​	subset: 'train'或者'test', 'all'，可选，选择要加载的训练集或数据集或全部

##### 		4. 数据集的返回值

​	datasets.base.Bunch(继承自字典)

​	dist["key"] = values

##### 5. 查看鸢尾花数据集load_iris

data: 特征数据数组

target:标签数组

DESCR: 数据描述

feature_names: 特征名

```python
from sklearn.datasets import load_iris


def datasetsDemo():
    """
    sklearn数据集使用
    :return:
    """
    # 获取数据集
    iris = load_iris()
    print("鸢尾花数据集：\n", iris)
    print("查看数据集描述：\n", iris["DESCR"])
    print("查看特征值的名字：\n", iris.feature_names)
    print("查看特征值：\n", iris.data, iris.data.shape)
    return None


if __name__ == '__main__':
    # 代码1：sklearn数据集使用
    datasetsDemo()
```

#### 2.1.3 数据集的划分

机器学习一般将数据集划分为两部分

- 训练数据：用于训练，构建模型
- 测试数据：在模型检验时使用，用于评估模型是否有效  测试集 20%~30%
- 训练集特征值x_train, 测试集特征值y_test, 训练集目标值y_train, 测试集目标值y_test
- **数据集划分api**：sklearn.modelselection.traintest_split()

```python
from sklearn.model_selection import train_test_split
# 数据集划分
# test-size:训练集取20%
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=22)
print("训练集的特征值：\n", x_train, x_train.shape)
```



### 2.2 特征工程

#### 2.2.1 什么是特征工程

​	sklearn	特征工程

​	pandas	数据清洗、数据处理

​		特征抽取/特征提取：机器学习算法 - 统计方法 - 数学公式 - 文本类型 -> 数值

​		特征预处理

​		特征降维

#### 2.2.2 特征提取

将任意数据转换成可用于机器学习的数字特征。

**sklearn.feature_extraction**

##### 1. 字典特征提取

**sklearn.feature_extraction.DictVectorizer(sparse = True)**

将字典转换为数值，返回sparse稀疏矩阵。（将非0值按矩阵位置表现出来）

```python
from sklearn.feature_extraction import DictVectorizer
def dict_demo():
    """
    字典特征提取
    :return:
    """
    data = [{'city': '北京', 'temperature': 100}, {'city': '上海', 'temperature': 60}, {'city': '深圳', 'temperature': 30}]
    # 1. 实例化转换器类
    transfer = DictVectorizer(sparse=False)

    # 2. 调用fit_transform()
    data_new = transfer.fit_transform(data)
    print("特征名称：\n", transfer.get_feature_names_out())
    print("data_new:\n", data_new)

    return None
```

![](C:\Users\周啸晨\AppData\Roaming\Typora\typora-user-images\1697554791622.png)

**应用场景：**

1. pclass, sex 数据集中类别特征比较多
   1. 将数据集的特征转换为字典类型
   2. 使用DictVectorizer转换

2. 本身拿到的数据就是字典类型

##### 2. 文本特征提取

- 将单词作为特征，对文本数据进行特征值化

- 特征：特征词

**方法1：CountVectorizer**  统计每个特征值出现的次数

```python
def count_demo():
    """
    文本特征抽取：CountVectorizer
    :return:
    """
    data = ["life is short, i like like python",
            "life is too long, i dislike python"]
    # 1. 实例化转换器类
    transfer = CountVectorizer()
    # 2. 调用fit_transform方法
    # 使用sparse类中的toarray()方法
    data_new = transfer.fit_transform(data)
    print("特征名称：\n", transfer.get_feature_names_out())
    print("data_new:\n", data_new.toarray())
    return None
```

![1697556134154](C:\Users\周啸晨\AppData\Roaming\Typora\typora-user-images\1697556134154.png)

